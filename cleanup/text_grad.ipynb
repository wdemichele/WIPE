{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textgradNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pacy (c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\wmichele\\\\appdata\\\\local\\\\anaconda3\\\\envs\\\\nw3\\\\lib\\\\site-packages\\\\numpy-1.23.4.dist-info\\\\METADATA'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading textgrad-0.1.5.tar.gz (65 kB)\n",
      "     ---------------------------------------- 0.0/65.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.7/65.7 kB 3.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting openai>=1.23.6 (from textgrad)\n",
      "  Obtaining dependency information for openai>=1.23.6 from https://files.pythonhosted.org/packages/5e/4d/affea11bd85ca69d9fdd15567495bb9088ac1c37498c95cb42d9ecd984ed/openai-1.43.0-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tenacity>=8.2.3 (from textgrad)\n",
      "  Obtaining dependency information for tenacity>=8.2.3 from https://files.pythonhosted.org/packages/b6/cb/b86984bed139586d01532a587464b5805f12e397594f19f931c4c2fbfa61/tenacity-9.0.0-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting python-dotenv>=1.0.0 (from textgrad)\n",
      "  Obtaining dependency information for python-dotenv>=1.0.0 from https://files.pythonhosted.org/packages/6a/3e/b68c118422ec867fa7ab88444e1274aa40681c606d59ac27de5a5588f082/python_dotenv-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pandas>=1.5.3 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from textgrad) (2.0.3)\n",
      "Collecting platformdirs>=3.11.0 (from textgrad)\n",
      "  Obtaining dependency information for platformdirs>=3.11.0 from https://files.pythonhosted.org/packages/68/13/2aa1f0e1364feb2c9ef45302f387ac0bd81484e9c9a4c5688a322fbdfd08/platformdirs-4.2.2-py3-none-any.whl.metadata\n",
      "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: datasets>=2.14.6 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from textgrad) (2.14.6)\n",
      "Collecting diskcache>=5.6.3 (from textgrad)\n",
      "  Obtaining dependency information for diskcache>=5.6.3 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting graphviz>=0.20.3 (from textgrad)\n",
      "  Obtaining dependency information for graphviz>=0.20.3 from https://files.pythonhosted.org/packages/00/be/d59db2d1d52697c6adc9eacaf50e8965b6345cc143f671e1ed068818d5cf/graphviz-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting gdown>=5.2.0 (from textgrad)\n",
      "  Obtaining dependency information for gdown>=5.2.0 from https://files.pythonhosted.org/packages/54/70/e07c381e6488a77094f04c85c9caf1c8008cdc30778f7019bc52e5285ef0/gdown-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from textgrad) (10.0.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from textgrad) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (1.23.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (14.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (4.65.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (0.17.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from datasets>=2.14.6->textgrad) (6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from gdown>=5.2.0->textgrad) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from gdown>=5.2.0->textgrad) (3.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from openai>=1.23.6->textgrad) (4.1.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from openai>=1.23.6->textgrad) (1.8.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.23.6->textgrad)\n",
      "  Obtaining dependency information for jiter<1,>=0.4.0 from https://files.pythonhosted.org/packages/48/b0/d4d684022f835b87bfdf6d3b33543935345675e661a2720757871f7eb93e/jiter-0.5.0-cp39-none-win_amd64.whl.metadata\n",
      "  Downloading jiter-0.5.0-cp39-none-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from openai>=1.23.6->textgrad) (1.10.11)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from openai>=1.23.6->textgrad) (1.3.0)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai>=1.23.6->textgrad)\n",
      "  Obtaining dependency information for typing-extensions<5,>=4.11 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from httpx->textgrad) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from httpx->textgrad) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from httpx->textgrad) (3.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from httpcore==1.*->httpx->textgrad) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from pandas>=1.5.3->textgrad) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from pandas>=1.5.3->textgrad) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from pandas>=1.5.3->textgrad) (2023.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.23.6->textgrad) (1.1.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from aiohttp->datasets>=2.14.6->textgrad) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from aiohttp->datasets>=2.14.6->textgrad) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from aiohttp->datasets>=2.14.6->textgrad) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from aiohttp->datasets>=2.14.6->textgrad) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wmichele\\appdata\\local\\anaconda3\\envs\\nw3\\lib\\site-packages (from aiohttp->datasets>=2.14.6->textgrad) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "%pip install textgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import concurrent\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import textgrad as tg\n",
    "from textgrad.tasks import load_task, DataLoader\n",
    "import numpy as np\n",
    "import csv\n",
    "import random\n",
    "import pandas as pd\n",
    "from textgrad.variable import Variable\n",
    "from loss import MultiFieldTokenParsedEvaluation\n",
    "from textgrad.autograd import StringBasedFunction\n",
    " \n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    " \n",
    "def load_dataset(filepath, evaluation_api, train_size = 0.2, val_size = 0.4, test_size = 0.4):\n",
    "    tuples_list = []\n",
    "    with open(filepath, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            sentence, number = row\n",
    "            tuples_list.append((sentence, number))\n",
    " \n",
    "    data = tuple(tuples_list)\n",
    "    total = len(data)\n",
    "    train_end = int(total * train_size)\n",
    "    val_end = train_end + int(total * val_size)\n",
    "   \n",
    "    train_data = data[:train_end]\n",
    "    val_data = data[train_end:val_end]\n",
    "    test_data = data[val_end:]\n",
    " \n",
    "    role_descriptions = [\n",
    "            \"Transcript for the task\",\n",
    "            \"Ground truth summarization\",\n",
    "            \"Summarization from the language model\"\n",
    "        ]\n",
    "   \n",
    "    evaluation_instruction = \"Below is a question from a transcript summarization task, the ground truth summarization, and final summarization prediction. Is the final summarization prediction correct, i.e. the same as the ground truth answer? Say only 1 (yes) or 0 (no). Return your response within <ACCURACY> </ACCURACY> tags. e.g.<ACCURACY> 0 </ACCURACY> or <ACCURACY> 1 </ACCURACY>.\"\n",
    "    eval_instruction = tg.Variable(evaluation_instruction, requires_grad=False, role_description=\"evaluation instruction for the task\")\n",
    " \n",
    "    eval_fn = MultiFieldTokenParsedEvaluation(\n",
    "        eval_instruction,\n",
    "        role_descriptions=role_descriptions,\n",
    "        engine=evaluation_api,\n",
    "        parse_tags=[\"<ACCURACY>\", \"</ACCURACY>\"]\n",
    "    )\n",
    "    return train_data, val_data, test_data, eval_fn\n",
    " \n",
    "def load_blog_dataset(filepath):\n",
    "    tuple_list = []\n",
    "    with open(filepath, mode='r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            sentence, number = row\n",
    "            tuple_list.append((sentence, number))\n",
    "           \n",
    "    return train_data, val_data, test_data, eval_data\n",
    " \n",
    "def eval_sample(item, eval_fn, model):\n",
    "    x, y = item\n",
    "    x = tg.Variable(x, requires_grad=False, role_description=\"query to the language model\")\n",
    "    y = tg.Variable(y, requires_grad=False, role_description=\"correct answer for the query\")\n",
    "    response = model(x)\n",
    "   \n",
    "    try:\n",
    "        eval_output_variable = eval_fn(inputs=dict(prediction=response, ground_truth_answer=y))\n",
    "        return int(eval_output_variable.value)\n",
    "   \n",
    "    except:\n",
    "        eval_output_variable = eval_fn([x, y, response])\n",
    "        eval_output_parsed = eval_fn.parse_output(eval_output_variable)\n",
    "       \n",
    "        return int(eval_output_parsed)\n",
    " \n",
    " \n",
    "def eval_dataset(test_set, eval_fn, model, max_samples=None):\n",
    "    if max_samples is None:\n",
    "        max_samples = len(test_set)\n",
    " \n",
    "    accuracy_list = []\n",
    "   \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        futures = []  \n",
    "        for _, sample in enumerate(test_set):\n",
    " \n",
    "            future = executor.submit(eval_sample, sample, eval_fn, model)\n",
    "            futures.append(future)\n",
    "            if len(futures) >= max_samples:\n",
    "                break\n",
    "        tqdm_loader = tqdm(concurrent.futures.as_completed(futures), total=len(futures), position=0)\n",
    "        for future in tqdm_loader:\n",
    "            acc_item = future.result()\n",
    "            accuracy_list.append(acc_item)\n",
    "            tqdm_loader.set_description(f\"Accuracy: {np.mean(accuracy_list)}\")\n",
    "   \n",
    "    return accuracy_list\n",
    " \n",
    " \n",
    "def run_validation_revert(system_prompt: tg.Variable, results, model, eval_fn, val_set):\n",
    "    val_performance = np.mean(eval_dataset(val_set, eval_fn, model))\n",
    "    previous_performance = np.mean(results[\"validation_acc\"][-1])\n",
    "    print(\"val_performance: \", val_performance)\n",
    "    print(\"previous_performance: \", previous_performance)\n",
    "    previous_prompt = results[\"prompt\"][-1]\n",
    "   \n",
    "    if val_performance < previous_performance:\n",
    "        print(f\"rejected prompt: {system_prompt.value}\")\n",
    "        system_prompt.set_value(previous_prompt)  \n",
    "        val_performance = previous_performance\n",
    "   \n",
    "    results[\"validation_acc\"].append(val_performance)\n",
    "    return val_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(12)\n",
    " \n",
    "llm_api_eval = tg.get_engine(engine_name=\"gpt-4o\")\n",
    " \n",
    "llm_api_test = tg.get_engine(engine_name=\"gpt-3.5-turbo-0125\")\n",
    " \n",
    "tg.set_backward_engine(llm_api_eval, override=True)\n",
    " \n",
    "train_set, val_set, test_set, eval_fn = load_dataset(\"./mkt_data.csv\", llm_api_eval)\n",
    " \n",
    "print(\"Train/Val/Test Set Lengths: \", len(train_set), len(val_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=3, shuffle=True)\n",
    " \n",
    "system_prompt = tg.Variable(STARTING_SYSTEM_PROMPT,\n",
    "                            requires_grad=True,\n",
    "                            role_description=\"system prompt to the language model\")  \n",
    " \n",
    "model_evaluation = tg.BlackboxLLM(llm_api_eval, system_prompt)\n",
    " \n",
    "system_prompt = tg.Variable(STARTING_SYSTEM_PROMPT,\n",
    "                            requires_grad=True,  \n",
    "                            role_description=\"structured system prompt to a somewhat capable language model that specifies the behavior and strategies for the QA task\")  # Descrizione del ruolo della variabile\n",
    " \n",
    "model = tg.BlackboxLLM(llm_api_test, system_prompt)\n",
    " \n",
    "optimizer = tg.TextualGradientDescent(engine=llm_api_eval, parameters=[system_prompt])\n",
    " \n",
    "results = {\"test_acc\": [], \"prompt\": [], \"validation_acc\": []}\n",
    "results[\"test_acc\"].append(eval_dataset(test_set, eval_fn, model))\n",
    "results[\"validation_acc\"].append(eval_dataset(val_set, eval_fn, model))\n",
    "results[\"prompt\"].append(system_prompt.get_value())\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    for steps, (batch_x, batch_y) in enumerate((pbar := tqdm(train_loader, position=0))):\n",
    "        pbar.set_description(f\"Training step {steps}. Epoch {epoch}\")\n",
    "        optimizer.zero_grad()\n",
    "        losses = []\n",
    "        for (x, y) in zip(batch_x, batch_y):\n",
    "            x = tg.Variable(x, requires_grad=False, role_description=\"query to the language model\")\n",
    "            y = tg.Variable(y, requires_grad=False, role_description=\"correct answer for the query\")\n",
    "            response = model(x)\n",
    "            try:\n",
    "                eval_output_variable = eval_fn(inputs=dict(prediction=response, ground_truth_answer=y))\n",
    "            except:\n",
    "                eval_output_variable = eval_fn([x, y, response])\n",
    "            losses.append(eval_output_variable)\n",
    "        total_loss = tg.sum(losses)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "       \n",
    "        run_validation_revert(system_prompt, results, model, eval_fn, val_set)\n",
    "       \n",
    "        print(\"sys prompt: \", system_prompt)\n",
    "        test_acc = eval_dataset(test_set, eval_fn, model)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "        results[\"prompt\"].append(system_prompt.get_value())\n",
    "        if steps == 3:\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
