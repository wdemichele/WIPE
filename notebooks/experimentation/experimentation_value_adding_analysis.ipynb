{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "root_path = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
                "sys.path.append(root_path)\n",
                "import json\n",
                "import logging\n",
                "from pprint import pprint\n",
                "\n",
                "from typing import List, Tuple, Dict\n",
                "from collections import defaultdict\n",
                "import math\n",
                "from dataclasses import asdict\n",
                "from src.common.prompts.value_adding_analysis.gpt_components import VAPromptComponents\n",
                "\n",
                "\n",
                "ROOT_DIR = r\"C:\\Projects\\Research\\SWEEP\\SWEEP\"\n",
                "\n",
                "# Set up logging\n",
                "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
                "\n",
                "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "sys.path.append(root_path)\n",
                "\n",
                "from src.common.models import ActivityBreakdown, ValueAddingAnalysis, ProcessModel\n",
                "from src.value_adding_analysis import ValueClassificationComponentsGPT, compare_value_classifications, print_comparison_results\n",
                "\n",
                "def get_sectors(train=True) -> List[str]:\n",
                "    data_path = os.path.join(ROOT_DIR, \"data\", \"train\" if train else \"test\")\n",
                "    return [sector for sector in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, sector))]\n",
                "\n",
                "def get_activities(sector: str, train=True) -> List[str]:\n",
                "    sector_path = os.path.join(ROOT_DIR, \"data\", \"train\" if train else \"test\", sector)\n",
                "    return [activity for activity in os.listdir(sector_path) if os.path.isdir(os.path.join(sector_path, activity))]\n",
                "\n",
                "def get_file_paths(sector: str, activity: str, model_name: str, train=True) -> Tuple[str, str, str, str]:\n",
                "    data_path = os.path.join(ROOT_DIR, \"data\", \"train\" if train else \"test\", sector, activity)\n",
                "    test_path = os.path.join(ROOT_DIR, \"test\", \"results\", sector, activity)\n",
                "    \n",
                "    activity_breakdown_path = os.path.join(data_path, f\"{activity}_activity_breakdown.json\")\n",
                "    ground_truth_path = os.path.join(data_path, f\"{activity}_step_value_analysis.json\")\n",
                "    response_path = os.path.join(test_path, f\"{model_name}_response.json\")\n",
                "    \n",
                "    return test_path, activity_breakdown_path, ground_truth_path, response_path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def classify_value_adding(sector: str, activity: str, model: ValueClassificationComponentsGPT, model_name) -> None:\n",
                "    logging.info(f\"Processing sector: {sector}, activity: {activity}\")\n",
                "    \n",
                "    try:\n",
                "        # Load activity breakdown and ground truth\n",
                "        test_path, activity_breakdown_path, ground_truth_path, response_path = get_file_paths(sector, activity, model_name)\n",
                "        activity_breakdown: ActivityBreakdown = ActivityBreakdown.from_json(activity_breakdown_path)\n",
                "        ground_truth = ValueAddingAnalysis.from_json(ground_truth_path)\n",
                "        \n",
                "        activity_breakdown_dict = activity_breakdown.to_dict()\n",
                "        \n",
                "        logging.info(f\"Processing with model: {model_name}\")\n",
                "        \n",
                "        # Ensure test directory exists\n",
                "        os.makedirs(test_path, exist_ok=True)\n",
                "        \n",
                "        # Get model response\n",
                "        response = model.value_classification_step_level(activity_breakdown_dict)\n",
                "        model_value_adding_analysis: ValueAddingAnalysis = ValueAddingAnalysis.from_dict(activity, activity_breakdown_dict)\n",
                "        model_value_adding_analysis.classify_substeps(response)\n",
                "        try:\n",
                "            # Process model response\n",
                "            comparison_metrics = compare_value_classifications(model_value_adding_analysis, ground_truth)\n",
                "        except:\n",
                "            comparison_metrics = None\n",
                "        \n",
                "        response_dict = {\n",
                "            \"model\": {\n",
                "                \"name\": model_name,\n",
                "                \"components\": model.prompt_components[\"_raw_input\"]\n",
                "            },\n",
                "            \"response\": response,\n",
                "            \"metrics\": comparison_metrics.to_dict()\n",
                "        }\n",
                "        \n",
                "        # Save results\n",
                "        with open(f\"experiment\\{activity}_experiment.json\", 'w') as f:\n",
                "            json.dump(response_dict, f, indent=4)\n",
                "        \n",
                "        logging.info(f\"Successfully processed and saved results for {sector}/{activity} with {model_name}\")\n",
                "    \n",
                "    except Exception as e:\n",
                "        logging.error(f\"Error processing {sector}/{activity}: {str(e)}\")\n",
                "        \n",
                "def save_model_configurations(models: Dict[str, ValueClassificationComponentsGPT], llm_version: str):\n",
                "    \"\"\"\n",
                "    Save the configuration of each model as a JSON file.\n",
                "    \n",
                "    :param models: Dictionary of model names and their corresponding ValueClassificationComponentsGPT instances\n",
                "    :param llm_version: Version of the LLM being used (e.g., \"gpt-4\")\n",
                "    \"\"\"\n",
                "    output_dir = os.path.join(\"test\", \"models\")\n",
                "    os.makedirs(output_dir, exist_ok=True)\n",
                "    \n",
                "    for model_name, model in models.items():\n",
                "        config = {\n",
                "            \"model_name\": model_name,\n",
                "            \"prompt_components\": model.prompt_components,\n",
                "            \"llm_version\": llm_version\n",
                "        }\n",
                "        \n",
                "        file_name = f\"{model_name}.json\"\n",
                "        file_path = os.path.join(output_dir, file_name)\n",
                "        \n",
                "        with open(file_path, 'w') as f:\n",
                "            json.dump(config, f, indent=2)\n",
                "        \n",
                "        print(f\"Saved configuration for {model_name} to {file_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "models = [\n",
                "        {\n",
                "            \"name\": \"GPT-3.5-Value-Classification-Experiment_Lean\",\n",
                "            \"components\": VAPromptComponents.from_dict({\n",
                "                \"role_description\": \"lean_expert\",\n",
                "                \"task_description\": \"efficiency_focused\",\n",
                "                \"classification_types\": \"custom\",\n",
                "                \"function_definition\": \"detailed\",\n",
                "                \"parsing_instructions\": \"holistic\",\n",
                "                \"output_format\": \"structured\",\n",
                "                \"example_output\": \"custom_process\",\n",
                "                \"additional_guidelines\": \"lean_principles\"\n",
                "            })\n",
                "        },\n",
                "        {\n",
                "            \"name\": \"GPT-3.5-Value-Classification-Process_Engineer_Technical\",\n",
                "            \"components\": VAPromptComponents.from_dict({\n",
                "                \"role_description\": \"process_engineer\",\n",
                "                \"task_description\": \"standard\",\n",
                "                \"classification_types\": \"detailed\",\n",
                "                \"function_definition\": \"basic\",\n",
                "                \"parsing_instructions\": \"sequential\",\n",
                "                \"output_format\": \"basic\",\n",
                "                \"example_output\": \"complex_process\"\n",
                "            })\n",
                "        },\n",
                "    ]\n",
                "\n",
                "model = models[0]\n",
                "\n",
                "value_classification_gpt = ValueClassificationComponentsGPT(model[\"components\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2024-10-08 15:35:54,817 - INFO - Processing sector: business, activity: b2b_sales\n",
                        "2024-10-08 15:35:54,830 - INFO - Processing with model: GPT-3.5-Value-Classification-Experiment_Lean\n",
                        "2024-10-08 15:35:58,948 - INFO - HTTP Request: POST https://datascience-openai-local.openai.azure.com//openai/deployments/gpt-35-turbo-16k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
                        "2024-10-08 15:36:03,927 - INFO - HTTP Request: POST https://datascience-openai-local.openai.azure.com//openai/deployments/gpt-35-turbo-16k/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
                        "2024-10-08 15:36:03,930 - INFO - Successfully processed and saved results for business/b2b_sales with GPT-3.5-Value-Classification-Experiment_Lean\n"
                    ]
                }
            ],
            "source": [
                "def main():\n",
                "    sectors = get_sectors()\n",
                "    for sector in sectors:\n",
                "        if sector != \"business\":\n",
                "            continue\n",
                "        activities = get_activities(sector)\n",
                "        for activity in activities:\n",
                "            if activity != \"b2b_sales\":\n",
                "                continue\n",
                "            classify_value_adding(sector, activity, value_classification_gpt, model[\"name\"])\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    main()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nw3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.15"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
